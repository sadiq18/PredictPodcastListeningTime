{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-05T15:13:44.960505Z",
     "iopub.status.busy": "2025-04-05T15:13:44.960196Z",
     "iopub.status.idle": "2025-04-05T15:13:45.271684Z",
     "shell.execute_reply": "2025-04-05T15:13:45.270810Z",
     "shell.execute_reply.started": "2025-04-05T15:13:44.960478Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T15:13:45.273377Z",
     "iopub.status.busy": "2025-04-05T15:13:45.272914Z",
     "iopub.status.idle": "2025-04-05T15:13:50.536150Z",
     "shell.execute_reply": "2025-04-05T15:13:50.535176Z",
     "shell.execute_reply.started": "2025-04-05T15:13:45.273343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, VotingRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T15:13:50.538280Z",
     "iopub.status.busy": "2025-04-05T15:13:50.537728Z",
     "iopub.status.idle": "2025-04-05T15:13:52.814402Z",
     "shell.execute_reply": "2025-04-05T15:13:52.813502Z",
     "shell.execute_reply.started": "2025-04-05T15:13:50.538253Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data reading \n",
    "train_data = pd.read_csv(\"/kaggle/input/playground-series-s5e4/train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/playground-series-s5e4/test.csv\")\n",
    "submission = pd.read_csv(\"/kaggle/input/playground-series-s5e4/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T15:13:52.815997Z",
     "iopub.status.busy": "2025-04-05T15:13:52.815715Z",
     "iopub.status.idle": "2025-04-05T15:13:52.819690Z",
     "shell.execute_reply": "2025-04-05T15:13:52.818944Z",
     "shell.execute_reply.started": "2025-04-05T15:13:52.815965Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configuration \n",
    "numerical_variables = ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
    "categorial_valiable = ['Podcast_Name', 'Episode_Title', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment'] \n",
    "target_variable = 'Listening_Time_minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T15:13:52.820565Z",
     "iopub.status.busy": "2025-04-05T15:13:52.820343Z",
     "iopub.status.idle": "2025-04-05T15:13:52.838113Z",
     "shell.execute_reply": "2025-04-05T15:13:52.837335Z",
     "shell.execute_reply.started": "2025-04-05T15:13:52.820547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Utility function \n",
    "\n",
    "def noise_removal(df):\n",
    "    df[\"Number_of_Ads\"] = df['Number_of_Ads'].apply(lambda x: x if x < 4 else 4)\n",
    "    df[\"Episode_Length_minutes\"] = df['Episode_Length_minutes'].apply(lambda x: x if x < 150 else 150)\n",
    "    return df\n",
    "\n",
    "def missing_value_imputation(df):\n",
    "    df[\"Episode_Length_minutes\"] = df.groupby(\"Podcast_Name\")[\"Episode_Length_minutes\"].transform(lambda x: x.fillna(x.mean()))\n",
    "    df[\"Guest_Popularity_percentage\"] = df.groupby(\"Podcast_Name\")[\"Guest_Popularity_percentage\"].transform(lambda x: x.fillna(x.mean()))\n",
    "    df[\"Number_of_Ads\"] = df[\"Number_of_Ads\"].fillna(2)\n",
    "    return df\n",
    "\n",
    "def bin_popularity(value):\n",
    "    if value < 20:\n",
    "        return 'Low'\n",
    "    elif value < 60:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "INTERACT = []\n",
    "def feature_engineering(train, test):\n",
    "    global numerical_variables\n",
    "    # Numerical columns \n",
    "    ## Interaction features\n",
    "    if len(INTERACT) > 0:\n",
    "        INTERACT.clear()\n",
    "    for i,c1 in enumerate(numerical_variables):\n",
    "        for j,c2 in enumerate(numerical_variables[i+1:]):\n",
    "            feature = f\"{c1}_{c2}\"\n",
    "            train[feature] = train[c1] * train[c2]\n",
    "            test[feature] = test[c1] * test[c2]\n",
    "            INTERACT.append(feature)\n",
    "    numerical_variables += INTERACT\n",
    "    print(f\"There are {len(INTERACT)} interaction features:\")\n",
    "    print(INTERACT)\n",
    "    \n",
    "    train['Host_Guest_Avg_Popularity'] = (train['Host_Popularity_percentage'] + train['Guest_Popularity_percentage']) / 2\n",
    "    test['Host_Guest_Avg_Popularity'] = (test['Host_Popularity_percentage'] + test['Guest_Popularity_percentage']) / 2\n",
    "    numerical_variables.append(\"Host_Guest_Avg_Popularity\")\n",
    "    \n",
    "    train[\"Host_Popularity_Level\"] = train[\"Host_Popularity_percentage\"].apply(bin_popularity)\n",
    "    test[\"Host_Popularity_Level\"] = test[\"Host_Popularity_percentage\"].apply(bin_popularity)\n",
    "    categorial_valiable.append(\"Host_Popularity_Level\")\n",
    "    train[\"Guest_Popularity_Level\"] = train[\"Guest_Popularity_percentage\"].apply(bin_popularity)\n",
    "    test[\"Guest_Popularity_Level\"] = test[\"Guest_Popularity_percentage\"].apply(bin_popularity)\n",
    "    categorial_valiable.append(\"Guest_Popularity_Level\")\n",
    "    \n",
    "    train['Has_Ads'] = train['Number_of_Ads'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    test['Has_Ads'] = test['Number_of_Ads'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    train[\"Ads_Per_Minutes\"] = train[\"Episode_Length_minutes\"] / (train[\"Number_of_Ads\"]+1)\n",
    "    test[\"Ads_Per_Minutes\"] = test[\"Episode_Length_minutes\"] / (test[\"Number_of_Ads\"]+1)\n",
    "    numerical_variables.append(\"Ads_Per_Minutes\")\n",
    "\n",
    "    # Categorical features\n",
    "    train['Is_Weekend'] = train['Publication_Day'].apply(lambda x: 1 if x == \"Saturday\" or x == \"Sunday\" else 0)\n",
    "    test['Is_Weekend'] = test['Publication_Day'].apply(lambda x: 1 if x == \"Saturday\" or x == \"Sunday\" else 0)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T15:13:52.839168Z",
     "iopub.status.busy": "2025-04-05T15:13:52.838892Z",
     "iopub.status.idle": "2025-04-05T15:13:52.853276Z",
     "shell.execute_reply": "2025-04-05T15:13:52.852486Z",
     "shell.execute_reply.started": "2025-04-05T15:13:52.839142Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode_features(train, test, categorical_features):\n",
    "    # Initialize the OneHotEncoder with drop='first'\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    \n",
    "    # Fit and transform the train set\n",
    "    train_encoded = encoder.fit_transform(train[categorical_features])\n",
    "    \n",
    "    # Transform the test set\n",
    "    test_encoded = encoder.transform(test[categorical_features])\n",
    "    \n",
    "    # Convert the encoded arrays to DataFrame\n",
    "    train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out(categorical_features))\n",
    "    test_encoded_df = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out(categorical_features))\n",
    "    \n",
    "    # Drop the original categorical columns from train and test DataFrames\n",
    "    train.drop(columns=categorical_features, inplace=True)\n",
    "    test.drop(columns=categorical_features, inplace=True)\n",
    "    \n",
    "    # Concatenate the one-hot encoded features to the original DataFrames\n",
    "    train = pd.concat([train, train_encoded_df], axis=1)\n",
    "    test = pd.concat([test, test_encoded_df], axis=1)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "def standardize_features(train, test, numerical_features):\n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit and transform the training data\n",
    "    train_scaled = scaler.fit_transform(train[numerical_features])\n",
    "    \n",
    "    # Transform the test data\n",
    "    test_scaled = scaler.transform(test[numerical_features])\n",
    "    \n",
    "    # Convert the scaled arrays back to DataFrames\n",
    "    train_scaled_df = pd.DataFrame(train_scaled, columns=numerical_features)\n",
    "    test_scaled_df = pd.DataFrame(test_scaled, columns=numerical_features)\n",
    "    \n",
    "    # Replace the original columns with the standardized columns\n",
    "    train[numerical_features] = train_scaled_df\n",
    "    test[numerical_features] = test_scaled_df\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T15:13:52.854365Z",
     "iopub.status.busy": "2025-04-05T15:13:52.854179Z",
     "iopub.status.idle": "2025-04-05T15:13:54.945875Z",
     "shell.execute_reply": "2025-04-05T15:13:54.945234Z",
     "shell.execute_reply.started": "2025-04-05T15:13:52.854348Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 interaction features:\n",
      "['Episode_Length_minutes_Host_Popularity_percentage', 'Episode_Length_minutes_Guest_Popularity_percentage', 'Episode_Length_minutes_Number_of_Ads', 'Host_Popularity_percentage_Guest_Popularity_percentage', 'Host_Popularity_percentage_Number_of_Ads', 'Guest_Popularity_percentage_Number_of_Ads']\n"
     ]
    }
   ],
   "source": [
    "# Data Processing \n",
    "train_data = noise_removal(train_data)\n",
    "test_data = noise_removal(test_data)\n",
    "train_data = missing_value_imputation(train_data)\n",
    "test_data = missing_value_imputation(test_data)\n",
    "train_data, test_data = feature_engineering(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T15:13:54.946931Z",
     "iopub.status.busy": "2025-04-05T15:13:54.946647Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = one_hot_encode_features(train_data, test_data, categorial_valiable)\n",
    "\n",
    "#train_data, test_data = standardize_features(train_data, test_data, numerical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = train_data.drop(['Listening_Time_minutes', 'id'], axis=1)\n",
    "y = train_data['Listening_Time_minutes']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(len(y_train), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_param_decision_tree = {'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 9}\n",
    "best_param_bagging_reg = {\"base_estimator\" : DecisionTreeRegressor(max_depth=8, random_state=42), \"n_estimators\": 300}\n",
    "best_param_rf = {\"max_depth\" : 9, \"min_samples_split\" : 8, \"min_samples_leaf\" : 9, \"n_estimators\" : 300}\n",
    "best_param_xg = { \"booster\": \"dart\",\n",
    "    \"lambda\": 9.770320148460564e-08,\n",
    "    \"alpha\": 1.612824838455072e-05,\n",
    "    \"subsample\": 0.8609881565231172,\n",
    "    \"colsample_bytree\": 0.8432633524521188,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"eta\": 0.42989406584229434,\n",
    "    \"gamma\": 0.000734224353473736,\n",
    "    \"grow_policy\": \"lossguide\",\n",
    "    \"num_boost_round\": 2756}\n",
    "best_param_lgb = {'booster': 'dart',\n",
    "     'lambda': 1.0688566030752065e-08,\n",
    "     'alpha': 2.0008470252864347e-07,\n",
    "     'subsample': 0.7258455740008215,\n",
    "     'colsample_bytree': 0.9669207998867171,\n",
    "     'max_depth': 8,\n",
    "     'min_child_weight': 2,\n",
    "     'eta': 0.41816603896355214,\n",
    "     'gamma': 0.055128970324283245,\n",
    "     'grow_policy': 'lossguide',\n",
    "     'num_boost_round': 872,\n",
    "     'device': 'gpu',\n",
    "     'verbose': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# BaggingRegressor = 13.24550\n",
    "best_bagging_model = BaggingRegressor(**best_param_bagging_reg, random_state=42, n_jobs=-1, verbose=10)\n",
    "# RandomForestRegressor = 13.21520\n",
    "best_rf_model = RandomForestRegressor(**best_param_rf, random_state=42, n_jobs=-1, verbose=10)\n",
    "# DecisionTreeRegressor = 13.25657\n",
    "best_tree_model = DecisionTreeRegressor(random_state=42, **best_param_decision_tree)\n",
    "# XGBRegressor : 13.21074\n",
    "best_param_xg[\"tree_method\"] = \"gpu_hist\" #ensure GPU\n",
    "best_param_xg[\"gpu_id\"] = 0\n",
    "best_param_xg[\"predictor\"] = \"gpu_predictor\"\n",
    "best_xgb_model = XGBRegressor(**best_param_xg)\n",
    "# LGBMRegressor = 13.08369\n",
    "best_param_lgb[\"device\"] = \"gpu\" #ensure GPU\n",
    "best_param_lgb['verbose'] = -1\n",
    "best_lgbm_model = LGBMRegressor(**best_param_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a VotingClassifier with the best estimators\n",
    "voting_clf = VotingRegressor(\n",
    "    estimators=[\n",
    "        ('tree', best_tree_model),\n",
    "        ('xg', best_xgb_model),\n",
    "        ('lgb', best_lgbm_model),\n",
    "        ('rf', best_rf_model),\n",
    "        ('bag', best_bagging_model)\n",
    "    ],\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "# Fit the VotingClassifier on your resampled training data\n",
    "#voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2025-04-05T16:06:24.339026Z",
     "shell.execute_reply": "2025-04-05T16:06:24.337992Z",
     "shell.execute_reply.started": "2025-04-05T15:14:03.303780Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 9 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   41.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 10 of 300\n",
      "building tree 11 of 300\n",
      "building tree 12 of 300\n",
      "building tree 13 of 300\n",
      "building tree 14 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 15 of 300\n",
      "building tree 16 of 300\n",
      "building tree 17 of 300\n",
      "building tree 18 of 300\n",
      "building tree 19 of 300\n",
      "building tree 20 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 21 of 300\n",
      "building tree 22 of 300\n",
      "building tree 23 of 300\n",
      "building tree 24 of 300\n",
      "building tree 25 of 300\n",
      "building tree 26 of 300\n",
      "building tree 27 of 300\n",
      "building tree 28 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 29 of 300\n",
      "building tree 30 of 300\n",
      "building tree 31 of 300\n",
      "building tree 32 of 300\n",
      "building tree 33 of 300\n",
      "building tree 34 of 300\n",
      "building tree 35 of 300\n",
      "building tree 36 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 37 of 300\n",
      "building tree 38 of 300\n",
      "building tree 39 of 300\n",
      "building tree 40 of 300\n",
      "building tree 41 of 300\n",
      "building tree 42 of 300\n",
      "building tree 43 of 300\n",
      "building tree 44 of 300\n",
      "building tree 45 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 46 of 300\n",
      "building tree 47 of 300\n",
      "building tree 48 of 300\n",
      "building tree 49 of 300\n",
      "building tree 50 of 300\n",
      "building tree 51 of 300\n",
      "building tree 52 of 300\n",
      "building tree 53 of 300\n",
      "building tree 54 of 300\n",
      "building tree 55 of 300\n",
      "building tree 56 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  4.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 57 of 300\n",
      "building tree 58 of 300\n",
      "building tree 59 of 300\n",
      "building tree 60 of 300\n",
      "building tree 61 of 300\n",
      "building tree 62 of 300\n",
      "building tree 63 of 300\n",
      "building tree 64 of 300\n",
      "building tree 65 of 300\n",
      "building tree 66 of 300\n",
      "building tree 67 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed:  5.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 68 of 300\n",
      "building tree 69 of 300\n",
      "building tree 70 of 300\n",
      "building tree 71 of 300\n",
      "building tree 72 of 300\n",
      "building tree 73 of 300\n",
      "building tree 74 of 300\n",
      "building tree 75 of 300\n",
      "building tree 76 of 300\n",
      "building tree 77 of 300\n",
      "building tree 78 of 300\n",
      "building tree 79 of 300\n",
      "building tree 80 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  7.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 81 of 300\n",
      "building tree 82 of 300\n",
      "building tree 83 of 300\n",
      "building tree 84 of 300\n",
      "building tree 85 of 300\n",
      "building tree 86 of 300\n",
      "building tree 87 of 300\n",
      "building tree 88 of 300\n",
      "building tree 89 of 300\n",
      "building tree 90 of 300\n",
      "building tree 91 of 300\n",
      "building tree 92 of 300\n",
      "building tree 93 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  8.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 94 of 300\n",
      "building tree 95 of 300\n",
      "building tree 96 of 300\n",
      "building tree 97 of 300\n",
      "building tree 98 of 300\n",
      "building tree 99 of 300\n",
      "building tree 100 of 300\n",
      "building tree 101 of 300\n",
      "building tree 102 of 300\n",
      "building tree 103 of 300\n",
      "building tree 104 of 300\n",
      "building tree 105 of 300\n",
      "building tree 106 of 300\n",
      "building tree 107 of 300\n",
      "building tree 108 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed:  9.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 109 of 300\n",
      "building tree 110 of 300\n",
      "building tree 111 of 300\n",
      "building tree 112 of 300\n",
      "building tree 113 of 300\n",
      "building tree 114 of 300\n",
      "building tree 115 of 300\n",
      "building tree 116 of 300\n",
      "building tree 117 of 300\n",
      "building tree 118 of 300\n",
      "building tree 119 of 300\n",
      "building tree 120 of 300\n",
      "building tree 121 of 300\n",
      "building tree 122 of 300\n",
      "building tree 123 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 10.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 124 of 300\n",
      "building tree 125 of 300\n",
      "building tree 126 of 300\n",
      "building tree 127 of 300\n",
      "building tree 128 of 300\n",
      "building tree 129 of 300\n",
      "building tree 130 of 300\n",
      "building tree 131 of 300\n",
      "building tree 132 of 300\n",
      "building tree 133 of 300\n",
      "building tree 134 of 300\n",
      "building tree 135 of 300\n",
      "building tree 136 of 300\n",
      "building tree 137 of 300\n",
      "building tree 138 of 300\n",
      "building tree 139 of 300\n",
      "building tree 140 of 300\n",
      "building tree 141 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 12.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 142 of 300\n",
      "building tree 143 of 300\n",
      "building tree 144 of 300\n",
      "building tree 145 of 300\n",
      "building tree 146 of 300\n",
      "building tree 147 of 300\n",
      "building tree 148 of 300\n",
      "building tree 149 of 300\n",
      "building tree 150 of 300\n",
      "building tree 151 of 300\n",
      "building tree 152 of 300\n",
      "building tree 153 of 300\n",
      "building tree 154 of 300\n",
      "building tree 155 of 300\n",
      "building tree 156 of 300\n",
      "building tree 157 of 300\n",
      "building tree 158 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 13.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 159 of 300\n",
      "building tree 160 of 300\n",
      "building tree 161 of 300\n",
      "building tree 162 of 300\n",
      "building tree 163 of 300\n",
      "building tree 164 of 300\n",
      "building tree 165 of 300\n",
      "building tree 166 of 300\n",
      "building tree 167 of 300\n",
      "building tree 168 of 300\n",
      "building tree 169 of 300\n",
      "building tree 170 of 300\n",
      "building tree 171 of 300\n",
      "building tree 172 of 300\n",
      "building tree 173 of 300\n",
      "building tree 174 of 300\n",
      "building tree 175 of 300\n",
      "building tree 176 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 15.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 177 of 300\n",
      "building tree 178 of 300\n",
      "building tree 179 of 300\n",
      "building tree 180 of 300\n",
      "building tree 181 of 300\n",
      "building tree 182 of 300\n",
      "building tree 183 of 300\n",
      "building tree 184 of 300\n",
      "building tree 185 of 300\n",
      "building tree 186 of 300\n",
      "building tree 187 of 300\n",
      "building tree 188 of 300\n",
      "building tree 189 of 300\n",
      "building tree 190 of 300\n",
      "building tree 191 of 300\n",
      "building tree 192 of 300\n",
      "building tree 193 of 300\n",
      "building tree 194 of 300\n",
      "building tree 195 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 16.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 196 of 300\n",
      "building tree 197 of 300\n",
      "building tree 198 of 300\n",
      "building tree 199 of 300\n",
      "building tree 200 of 300\n",
      "building tree 201 of 300\n",
      "building tree 202 of 300\n",
      "building tree 203 of 300\n",
      "building tree 204 of 300\n",
      "building tree 205 of 300\n",
      "building tree 206 of 300\n",
      "building tree 207 of 300\n",
      "building tree 208 of 300\n",
      "building tree 209 of 300\n",
      "building tree 210 of 300\n",
      "building tree 211 of 300\n",
      "building tree 212 of 300\n",
      "building tree 213 of 300\n",
      "building tree 214 of 300\n",
      "building tree 215 of 300\n",
      "building tree 216 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 18.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 217 of 300\n",
      "building tree 218 of 300\n",
      "building tree 219 of 300\n",
      "building tree 220 of 300\n",
      "building tree 221 of 300\n",
      "building tree 222 of 300\n",
      "building tree 223 of 300\n",
      "building tree 224 of 300\n",
      "building tree 225 of 300\n",
      "building tree 226 of 300\n",
      "building tree 227 of 300\n",
      "building tree 228 of 300\n",
      "building tree 229 of 300\n",
      "building tree 230 of 300\n",
      "building tree 231 of 300\n",
      "building tree 232 of 300\n",
      "building tree 233 of 300\n",
      "building tree 234 of 300\n",
      "building tree 235 of 300\n",
      "building tree 236 of 300\n",
      "building tree 237 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 234 tasks      | elapsed: 20.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 238 of 300\n",
      "building tree 239 of 300\n",
      "building tree 240 of 300\n",
      "building tree 241 of 300\n",
      "building tree 242 of 300\n",
      "building tree 243 of 300\n",
      "building tree 244 of 300\n",
      "building tree 245 of 300\n",
      "building tree 246 of 300\n",
      "building tree 247 of 300\n",
      "building tree 248 of 300\n",
      "building tree 249 of 300\n",
      "building tree 250 of 300\n",
      "building tree 251 of 300\n",
      "building tree 252 of 300\n",
      "building tree 253 of 300\n",
      "building tree 254 of 300\n",
      "building tree 255 of 300\n",
      "building tree 256 of 300\n",
      "building tree 257 of 300\n",
      "building tree 258 of 300\n",
      "building tree 259 of 300\n",
      "building tree 260 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 257 tasks      | elapsed: 22.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 261 of 300\n",
      "building tree 262 of 300\n",
      "building tree 263 of 300\n",
      "building tree 264 of 300\n",
      "building tree 265 of 300\n",
      "building tree 266 of 300\n",
      "building tree 267 of 300\n",
      "building tree 268 of 300\n",
      "building tree 269 of 300\n",
      "building tree 270 of 300\n",
      "building tree 271 of 300\n",
      "building tree 272 of 300\n",
      "building tree 273 of 300\n",
      "building tree 274 of 300\n",
      "building tree 275 of 300\n",
      "building tree 276 of 300\n",
      "building tree 277 of 300\n",
      "building tree 278 of 300\n",
      "building tree 279 of 300\n",
      "building tree 280 of 300\n",
      "building tree 281 of 300\n",
      "building tree 282 of 300\n",
      "building tree 283 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed: 24.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 284 of 300\n",
      "building tree 285 of 300\n",
      "building tree 286 of 300\n",
      "building tree 287 of 300\n",
      "building tree 288 of 300\n",
      "building tree 289 of 300\n",
      "building tree 290 of 300\n",
      "building tree 291 of 300\n",
      "building tree 292 of 300\n",
      "building tree 293 of 300\n",
      "building tree 294 of 300\n",
      "building tree 295 of 300\n",
      "building tree 296 of 300\n",
      "building tree 297 of 300\n",
      "building tree 298 of 300\n",
      "building tree 299 of 300\n",
      "building tree 300 of 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 26.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ....................... (4 of 5) Processing rf, total=26.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed: 25.1min\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed: 25.1min remaining: 25.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Voting] ...................... (5 of 5) Processing bag, total=25.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed: 25.2min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingRegressor(estimators=[(&#x27;tree&#x27;,\n",
       "                             DecisionTreeRegressor(max_depth=9,\n",
       "                                                   min_samples_leaf=9,\n",
       "                                                   min_samples_split=8,\n",
       "                                                   random_state=42)),\n",
       "                            (&#x27;xg&#x27;,\n",
       "                             XGBRegressor(alpha=1.612824838455072e-05,\n",
       "                                          base_score=None, booster=&#x27;dart&#x27;,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=0.8432633524521188,\n",
       "                                          device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_cat...\n",
       "                                           num_boost_round=872,\n",
       "                                           subsample=0.7258455740008215,\n",
       "                                           verbose=-1)),\n",
       "                            (&#x27;rf&#x27;,\n",
       "                             RandomForestRegressor(max_depth=9,\n",
       "                                                   min_samples_leaf=9,\n",
       "                                                   min_samples_split=8,\n",
       "                                                   n_estimators=300, n_jobs=-1,\n",
       "                                                   random_state=42,\n",
       "                                                   verbose=10)),\n",
       "                            (&#x27;bag&#x27;,\n",
       "                             BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=8,\n",
       "                                                                                   random_state=42),\n",
       "                                              n_estimators=300, n_jobs=-1,\n",
       "                                              random_state=42, verbose=10))],\n",
       "                verbose=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingRegressor</label><div class=\"sk-toggleable__content\"><pre>VotingRegressor(estimators=[(&#x27;tree&#x27;,\n",
       "                             DecisionTreeRegressor(max_depth=9,\n",
       "                                                   min_samples_leaf=9,\n",
       "                                                   min_samples_split=8,\n",
       "                                                   random_state=42)),\n",
       "                            (&#x27;xg&#x27;,\n",
       "                             XGBRegressor(alpha=1.612824838455072e-05,\n",
       "                                          base_score=None, booster=&#x27;dart&#x27;,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=0.8432633524521188,\n",
       "                                          device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_cat...\n",
       "                                           num_boost_round=872,\n",
       "                                           subsample=0.7258455740008215,\n",
       "                                           verbose=-1)),\n",
       "                            (&#x27;rf&#x27;,\n",
       "                             RandomForestRegressor(max_depth=9,\n",
       "                                                   min_samples_leaf=9,\n",
       "                                                   min_samples_split=8,\n",
       "                                                   n_estimators=300, n_jobs=-1,\n",
       "                                                   random_state=42,\n",
       "                                                   verbose=10)),\n",
       "                            (&#x27;bag&#x27;,\n",
       "                             BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=8,\n",
       "                                                                                   random_state=42),\n",
       "                                              n_estimators=300, n_jobs=-1,\n",
       "                                              random_state=42, verbose=10))],\n",
       "                verbose=100)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>tree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=9, min_samples_leaf=9, min_samples_split=8,\n",
       "                      random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xg</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(alpha=1.612824838455072e-05, base_score=None, booster=&#x27;dart&#x27;,\n",
       "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8432633524521188, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eta=0.42989406584229434, eval_metric=None, feature_types=None,\n",
       "             gamma=0.000734224353473736, gpu_id=0, grow_policy=&#x27;lossguide&#x27;,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             lambda=9.770320148460564e-08, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=8, max_leaves=None,\n",
       "             min_child_weight=6, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(alpha=2.0008470252864347e-07, booster=&#x27;dart&#x27;,\n",
       "              colsample_bytree=0.9669207998867171, device=&#x27;gpu&#x27;,\n",
       "              eta=0.41816603896355214, gamma=0.055128970324283245,\n",
       "              grow_policy=&#x27;lossguide&#x27;, lambda=1.0688566030752065e-08,\n",
       "              max_depth=8, min_child_weight=2, num_boost_round=872,\n",
       "              subsample=0.7258455740008215, verbose=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=9, min_samples_leaf=9, min_samples_split=8,\n",
       "                      n_estimators=300, n_jobs=-1, random_state=42, verbose=10)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>bag</label></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=8, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=8, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingRegressor(estimators=[('tree',\n",
       "                             DecisionTreeRegressor(max_depth=9,\n",
       "                                                   min_samples_leaf=9,\n",
       "                                                   min_samples_split=8,\n",
       "                                                   random_state=42)),\n",
       "                            ('xg',\n",
       "                             XGBRegressor(alpha=1.612824838455072e-05,\n",
       "                                          base_score=None, booster='dart',\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=0.8432633524521188,\n",
       "                                          device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_cat...\n",
       "                                           num_boost_round=872,\n",
       "                                           subsample=0.7258455740008215,\n",
       "                                           verbose=-1)),\n",
       "                            ('rf',\n",
       "                             RandomForestRegressor(max_depth=9,\n",
       "                                                   min_samples_leaf=9,\n",
       "                                                   min_samples_split=8,\n",
       "                                                   n_estimators=300, n_jobs=-1,\n",
       "                                                   random_state=42,\n",
       "                                                   verbose=10)),\n",
       "                            ('bag',\n",
       "                             BaggingRegressor(base_estimator=DecisionTreeRegressor(max_depth=8,\n",
       "                                                                                   random_state=42),\n",
       "                                              n_estimators=300, n_jobs=-1,\n",
       "                                              random_state=42, verbose=10))],\n",
       "                verbose=100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T16:06:24.340667Z",
     "iopub.status.busy": "2025-04-05T16:06:24.340300Z",
     "iopub.status.idle": "2025-04-05T16:06:24.344273Z",
     "shell.execute_reply": "2025-04-05T16:06:24.343341Z",
     "shell.execute_reply.started": "2025-04-05T16:06:24.340621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#y_val_pred = voting_clf.predict(X_val)\n",
    "#print('DecisionTreeRegressor validation Room mean square error:', np.sqrt(mean_squared_error(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T16:06:24.345577Z",
     "iopub.status.busy": "2025-04-05T16:06:24.345285Z",
     "iopub.status.idle": "2025-04-05T16:07:02.609433Z",
     "shell.execute_reply": "2025-04-05T16:07:02.608507Z",
     "shell.execute_reply.started": "2025-04-05T16:06:24.345550Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=4)]: Done 300 out of 300 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   29.0s remaining:   29.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   29.2s finished\n"
     ]
    }
   ],
   "source": [
    "X_test = test_data.drop(['id'], axis=1)\n",
    "test_predictions = voting_clf.predict(X_test)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'Listening_Time_minutes': test_predictions  # Predicted probabilities for rainfall\n",
    "})\n",
    "\n",
    "submission_df[\"Listening_Time_minutes\"] = submission_df[\"Listening_Time_minutes\"].clip(\n",
    "    lower=0, upper=test_data[\"Episode_Length_minutes\"])\n",
    "\n",
    "submission_df.to_csv(\"submission_VotingRegressor_04_05_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
